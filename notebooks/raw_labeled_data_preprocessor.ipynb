{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from flashtext import KeywordProcessor\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "# from pypac import PACSession, get_pac\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# import dask.dataframe as dd\n",
    "# import fastText\n",
    "# from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "# import torch\n",
    "# from torch import autograd\n",
    "from os.path import isfile\n",
    "import re\n",
    "from time import time\n",
    "from scipy import spatial\n",
    "import random as rand\n",
    "from random import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "new_labeled_data = json.load(codecs.open('../data/testData.json', 'r', 'utf-8-sig'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labeled_data = new_labeled_data['rasa_nlu_data']['common_examples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labeled_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_entity_dict = {}\n",
    "for item in new_labeled_data:\n",
    "    if item['intent'] not in intent_entity_dict:\n",
    "        intent_entity_dict[item['intent']] = set()\n",
    "    for entity in item['entities']:\n",
    "        intent_entity_dict[item['intent']].add(entity['entity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出用于分类的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df = []\n",
    "for t in new_labeled_data:\n",
    "    new_label_df.append({\n",
    "        'sentence': t['text'],\n",
    "        'event': t['intent']\n",
    "    })\n",
    "    \n",
    "new_label_df = pd.DataFrame(new_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_train, new_label_eval = train_test_split(new_label_df, test_size=0.3, stratify=new_label_df.event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df = pd.read_csv(\"../data/event_type_entity_extract_train.csv\", names=['id', 'sentence', 'event', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df['event'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df = pd.concat([new_label_df, original_train_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df.to_csv(\"../temp/cat_classification_train.csv\", index=False, header=False, columns=['id', 'sentence', 'event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_eval.to_csv(\"../temp/cat_classification_eval.csv\", index=False, header=False, columns=['id', 'sentence', 'event', 'answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出用于抽取实体的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t  in ['资金账户风险', '涉嫌欺诈', '业绩下滑', '信批违规', '涉嫌传销', '交易违规', '财务造假', '评级调整',\n",
    "       '重组失败', '涉嫌违法', '实控人股东变更', '不能履职', '涉嫌非法集资', '资产负面', '歇业停业',\n",
    "       '提现困难', '高管负面', '投诉维权', '失联跑路', '产品违规', '公司股市异常']:\n",
    "    intent_entity_dict[t]={'主体'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(intent_entity_dict, \"../temp/intent_entity_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "new_label_df = []\n",
    "for t in new_labeled_data:\n",
    "    intent = t['intent']\n",
    "    sentence = t['text']\n",
    "    entity_map = {}\n",
    "    contains_entity = set()\n",
    "    for entity in t['entities']:\n",
    "        new_label_df.append({\n",
    "            'sentence': sentence,\n",
    "            'query': intent+'__'+ entity['entity'],\n",
    "            'answer': entity['value']\n",
    "        })\n",
    "        contains_entity.add(entity['entity'])\n",
    "    contains_entity = [t for t in intent_entity_dict[intent] if t not in contains_entity]\n",
    "    if contains_entity:\n",
    "        for t in contains_entity:\n",
    "            new_label_df.append({\n",
    "                'sentence': sentence,\n",
    "                'query': intent+'__'+ t,\n",
    "                'answer': 'no_given'\n",
    "            })\n",
    "#     temp = list(intent_entity_dict.keys())\n",
    "#     temp.remove(intent)\n",
    "#     mock_intents = random.sample(temp, 6)\n",
    "#     for mock_intent in mock_intents:\n",
    "#         mock_entity = random.choice(list(intent_entity_dict[mock_intent]))\n",
    "#         for mock_entity in intent_entity_dict[mock_intent]:\n",
    "#             new_label_df.append({\n",
    "#                 'sentence': sentence,\n",
    "#                 'query': mock_intent+'__'+ mock_entity,\n",
    "#                 'answer': 'no_given'\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df = pd.DataFrame(new_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df['id'] = new_label_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_train, new_label_eval = train_test_split(new_label_df, test_size=0.3, stratify= new_label_df['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df = pd.read_csv(\"../data/event_type_entity_extract_train.csv\", names=['id', 'sentence', 'query', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df['query'] = original_train_df['query'].apply(lambda x: x+'__主体' if x !='其他' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df['query'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df = pd.concat([new_label_df, original_train_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_train_df.to_csv(\"../temp/cat_event_extraction_train.csv\", index=False, header=False, columns=['id', 'sentence', 'query', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_eval.to_csv(\"../temp/cat_event_extraction_eval.csv\", index=False, header=False, columns=['id', 'sentence', 'query', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(updated_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
